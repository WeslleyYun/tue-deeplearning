{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "workbook-task1.1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v_3Kdq4tqYC"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment1/workbook-task1.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5YOR6q_Z2-b"
   },
   "source": [
    "TODO: Modify this cell to add your group name, group number and your names and student IDs\n",
    "\n",
    "Group: 51\n",
    "\n",
    "Authors:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuVJoCROtogK",
    "outputId": "f49fc160-4541-4c83-9737-f669f8e5af5a"
   },
   "source": [
    "import requests\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "%pylab inline"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_x0WIjQ7togW"
   },
   "source": [
    "### Training data set\n",
    "\n",
    "For task 1 of Assignment 1 you need to use a specific data set prepared using images from the [Omniglot dataset](https://github.com/brendenlake/omniglot). The provided training data set contains 18.800 binary images of handwritten characters of size (28,28). Each of these images depicts one of 893 different characters from 29 different alphabets. Each image is accompanied by a label that is encoded as an interger $y\\in\\{0, 1, ..., 892\\}$ that indicate the caracter depicted in the image. The following cell provides code that loads the data from hardcoded URLs.\n",
    "\n",
    "You can use the code in this cell to load the dataset or download the data set from the given URLs to your local drive (or your Google drive) and modify the code to load the data from another location. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLCixBNZtogX",
    "outputId": "33814293-f8d2-4cc8-f739-083b9e374b50"
   },
   "source": [
    "def load_numpy_arr_from_url(url):\n",
    "    \"\"\"\n",
    "    Loads a numpy array from surfdrive. \n",
    "    \n",
    "    Input:\n",
    "    url: Download link of dataset \n",
    "    \n",
    "    Outputs:\n",
    "    dataset: numpy array with input features or labels\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return np.load(io.BytesIO(response.content)) \n",
    "    \n",
    "    \n",
    "    \n",
    "# Downloading may take a while..\n",
    "train_x = load_numpy_arr_from_url('https://surfdrive.surf.nl/files/index.php/s/tvQmLyY7MhVsADb/download')\n",
    "train_y = load_numpy_arr_from_url('https://surfdrive.surf.nl/files/index.php/s/z234AHrQqx9RVGH/download')\n",
    "\n",
    "print(f\"train_x shape: {train_x.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\\n\")\n",
    "train_x_ge = (train_x.reshape((-1,784))/255)\n",
    "train_x_ge1 = torch.from_numpy(train_x_ge)\n",
    "train_x_re = train_x_ge1.type(torch.FloatTensor)\n",
    "train_y_re = torch.from_numpy(train_y)\n",
    "print(train_x_re)\n",
    "print(train_y_re)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (18800, 28, 28)\n",
      "train_y shape: (18800,)\n",
      "\n",
      "tensor([[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        ...,\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]])\n",
      "tensor([  1,   1,   1,  ..., 964, 964, 964])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "940"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsyaadG4togZ"
   },
   "source": [
    "### Query data set\n",
    "\n",
    "For this task you need to use the following query data set. The dataset contains 100 sets of 6 images each. The images are also of hand written characters, however these characters are not present in the training data set. The characters in the query data set all come from the Greek alphabet that is not part of the set of alphabets in the training data. \n",
    "\n",
    "Each test set consists of 1 query image and 5 candidate images. All images are the same size (28x28). The test data is organized in two numpy arrays. One for the query images with shape (100, 1, 28, 28) and another for the candidate imagaes with shape (100, 5, 28, 28). \n",
    "\n",
    "The task is to develop a model that enables selecting the image which is depicting the same character as the anchor image out of 5 test images. These test images are declared in the `query_x` numpy array . \n",
    "\n",
    "Finally, we plot the first 5 cases in the query dataset. The first column corresponds with the anchor images of each of the 5 cases. All other images are test images from which the task is to recognize the anchor image. The image enclosed in a red box denotes the target image that your model should be able to recognize as the same class as the anchor image. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHZcmBr4togZ",
    "outputId": "e168005d-efc5-4919-9bed-ae1e6194bc05"
   },
   "source": [
    "query_dataset = load_numpy_arr_from_url(\"https://surfdrive.surf.nl/files/index.php/s/YGn5gb7unBEuCLB/download\")\n",
    "queries_true = load_numpy_arr_from_url(\"https://surfdrive.surf.nl/files/index.php/s/0sPeeIFB3W9RPZG/download\")\n",
    "\n",
    "queries, candidates_sets = np.split(query_dataset, [1], axis=1)\n",
    "\n",
    "print(f\"query images have shape: {queries.shape}\")\n",
    "print(f\"target sets have shape: {candidates_sets.shape}\")\n",
    "print(f\"ground truth: {queries_true.shape}\")"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query images have shape: (100, 1, 28, 28)\n",
      "target sets have shape: (100, 5, 28, 28)\n",
      "ground truth: (100,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hDzMPaZMtoga",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "76282bfd-591f-4512-afb9-8328509e937e"
   },
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def plot_case(caseID):\n",
    "    \"\"\"\n",
    "    Plots a single sample of the query dataset\n",
    "    \n",
    "    Inputs\n",
    "    caseID: Integer between 0 and 99, each corresponding to a single sample in the query dataset \n",
    "    \"\"\"\n",
    "    f, axes = plt.subplots(1, 6, figsize=(20,5))\n",
    "    \n",
    "    # plot anchor image\n",
    "    axes[0].imshow(queries[caseID, 0])\n",
    "    axes[0].set_title(f\"Anchor image case {caseID}\", fontsize=10)\n",
    "    \n",
    "    # show all test images images \n",
    "    [ax.imshow(candidates_sets[caseID, i]) for i, ax in enumerate(axes[1:])]\n",
    "    \n",
    "    \n",
    "    # Add the patch to the Axes\n",
    "    axes[queries_true[caseID]].add_patch(Rectangle((0,0),27,27,linewidth=2, edgecolor='r',facecolor='none'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# plot the first five samples of the query datset\n",
    "[plot_case(caseID) for caseID in range(5)] ;"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ObMV6qoI0vc9"
   },
   "source": [
    "##\n",
    "# Setting up fit and loss functions as in tutorial 2.1\n",
    "# \n",
    "\n",
    "#Use a train test split on original train set to check model performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x_re, train_y_re)\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    \n",
    "    output=model(xb)\n",
    "    loss = loss_func(output, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    _, preds = torch.max(output, 1)\n",
    "    corrects = torch.sum(preds == yb.data)\n",
    "    \n",
    "    return loss.item(), corrects, len(xb)\n",
    "\n",
    "from tqdm import tqdm\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        \n",
    "        # training process\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        sample_num=0\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            # forward\n",
    "            # backward and optimize only if in training phase\n",
    "            losses, corrects, nums = loss_batch(model, loss_func, xb, yb,opt)\n",
    "            \n",
    "            # statistics\n",
    "            running_loss += losses * xb.size(0)\n",
    "            running_corrects += corrects\n",
    "            sample_num+=nums\n",
    "            \n",
    "        train_loss = running_loss / sample_num\n",
    "        train_acc = running_corrects.double() / sample_num\n",
    "\n",
    "        \n",
    "        # validation process\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            sample_num=0\n",
    "            for xb, yb in valid_dl:\n",
    "                \n",
    "                # forward\n",
    "                losses, corrects, nums = loss_batch(model, loss_func, xb, yb)\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += losses * xb.size(0)\n",
    "                running_corrects += corrects\n",
    "                sample_num+=nums\n",
    "\n",
    "            val_loss = running_loss / sample_num\n",
    "            val_acc = running_corrects.double()/ sample_num\n",
    "            \n",
    "            \n",
    "        # print the results\n",
    "        print(\n",
    "            f'EPOCH: {epoch+1:0>{len(str(epochs))}}/{epochs}',\n",
    "            end=' '\n",
    "        )\n",
    "        print(f'LOSS: {train_loss:.4f}',f'ACC: {train_acc:.4f} ',end=' ')\n",
    "        print(f'VAL-LOSS: {val_loss:.4f}',f'VAL-ACC: {val_acc:.4f} ',end='\\n')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_test, y_test)\n",
    "\n",
    "bs=64\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-5bd180f25c76>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mclass\u001B[0m \u001B[0mLambda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModule\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     Lambda(preprocess),\n",
    "#\n",
    "#     # Conv Layer block 1\n",
    "#     nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "#     nn.BatchNorm2d(32),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Dropout(p=0.5),\n",
    "#     nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#     # Conv Layer block 2\n",
    "#     nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "#     nn.BatchNorm2d(128),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Dropout(p=0.5),\n",
    "#     nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#     # Conv Layer block 3\n",
    "#     nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "#     nn.BatchNorm2d(256),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Dropout(p=0.5),\n",
    "#     nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#     Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "#\n",
    "#     nn.Linear(2304, 1024),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(1024, 512),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(512, 965),\n",
    "# )\n",
    "\n",
    "class model_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(model_mod, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "            Lambda(preprocess),\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "\n",
    "            nn.Linear(2304, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 965),\n",
    "        )\n",
    "\n",
    "        self.last_layer = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "lr = 0.1\n",
    "opt = optim.SGD(model_mod.parameters(), lr=lr, momentum=0.9)\n",
    "epochs=30\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "fit(epochs, model_mod, loss_func, opt, train_dl, valid_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szy27W6PI0sY",
    "outputId": "a72e5b9b-fc69-4782-d140-3b336298f3e3"
   },
   "source": [
    "#other implementation\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "    nn.Linear(64, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 965),\n",
    "    \n",
    ")\n",
    "\n",
    "lr = 0.1\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "epochs=10\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:25,  2.87s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 01/10 LOSS: 6.8776 ACC: 0.0006  VAL-LOSS: 6.8794 VAL-ACC: 0.0002 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2/10 [00:05<00:22,  2.86s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 02/10 LOSS: 6.8693 ACC: 0.0010  VAL-LOSS: 6.8853 VAL-ACC: 0.0004 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3/10 [00:08<00:19,  2.85s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 03/10 LOSS: 6.8646 ACC: 0.0009  VAL-LOSS: 6.8910 VAL-ACC: 0.0004 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 4/10 [00:11<00:17,  2.91s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 04/10 LOSS: 6.8613 ACC: 0.0004  VAL-LOSS: 6.8942 VAL-ACC: 0.0004 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 50%|█████     | 5/10 [00:14<00:15,  3.03s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 05/10 LOSS: 6.8588 ACC: 0.0010  VAL-LOSS: 6.8972 VAL-ACC: 0.0002 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6/10 [00:18<00:12,  3.13s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 06/10 LOSS: 6.8569 ACC: 0.0009  VAL-LOSS: 6.9021 VAL-ACC: 0.0002 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 70%|███████   | 7/10 [00:21<00:09,  3.19s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 07/10 LOSS: 6.8558 ACC: 0.0007  VAL-LOSS: 6.9011 VAL-ACC: 0.0002 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8/10 [00:24<00:06,  3.23s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 08/10 LOSS: 6.8545 ACC: 0.0011  VAL-LOSS: 6.9045 VAL-ACC: 0.0002 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9/10 [00:28<00:03,  3.26s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 09/10 LOSS: 6.8538 ACC: 0.0007  VAL-LOSS: 6.9051 VAL-ACC: 0.0000 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "EPOCH: 10/10 LOSS: 6.8531 ACC: 0.0008  VAL-LOSS: 6.9052 VAL-ACC: 0.0000 \n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RqyseRnwjt4R"
   },
   "source": [
    "## #TODO Modify this function such that you implement you character recognition algorithm here\n",
    "## The test code bellow will call this function with the following parameters \n",
    "## query - the query image (28, 28)\n",
    "## candidates - numpy array of candidate images, shape (5, 28, 28)\n",
    "## return - sorted array of the indexes of the images based on the similarty to the query image \n",
    "def test_model(query, candidates):\n",
    "  # TODO: dummy output that should be substituted by values produced by your solution\n",
    "  sorted_indexes = np.array([1, 2, 3, 4, 5]) \n",
    "\n",
    "  return sorted_indexes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMvs5VZuky4Q",
    "outputId": "c7a18bd0-450c-4934-c872-1ee9f5052343"
   },
   "source": [
    "## test top-1\n",
    "def test_top_1(query, candidates, query_true):\n",
    "  sorted_indexes = test_model(query, candidates)\n",
    "  return query_true == sorted_indexes[0]\n",
    "\n",
    "## test top-3\n",
    "def test_top_3(query, candidates, query_true):\n",
    "  sorted_indexes = test_model(query, candidates)\n",
    "  return np.isin(query_true, sorted_indexes[:3])\n",
    "\n",
    "top_1_res = np.array([test_top_1(a, b, c) for (a, b, c) in zip(queries, candidates_sets, queries_true)])\n",
    "top_3_res = np.array([test_top_3(a, b, c) for (a, b, c) in zip(queries, candidates_sets, queries_true)])\n",
    "\n",
    "top_1 = np.count_nonzero(top_1_res) / queries.shape[0]\n",
    "print(f\"top-1 accuracy: {top_1}\")\n",
    "\n",
    "top_3 = np.count_nonzero(top_3_res) / queries.shape[0]\n",
    "print(f\"top-3 accuracy: {top_3}\")\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "top-1 accuracy: 0.25\n",
      "top-3 accuracy: 0.58\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bHSVcJvDZ2-g"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}